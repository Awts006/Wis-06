{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from matplotlib import pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = 'Train_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = [dirs+f \n",
    "             for f in os.listdir(dirs)\n",
    "             if os.path.isfile(os.path.join(dirs,f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20858"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "rawImages=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 1000/20858\n",
      "[INFO] processed 2000/20858\n",
      "[INFO] processed 3000/20858\n",
      "[INFO] processed 4000/20858\n",
      "[INFO] processed 5000/20858\n",
      "[INFO] processed 6000/20858\n",
      "[INFO] processed 7000/20858\n",
      "[INFO] processed 8000/20858\n",
      "[INFO] processed 9000/20858\n",
      "[INFO] processed 10000/20858\n",
      "[INFO] processed 11000/20858\n",
      "[INFO] processed 12000/20858\n",
      "[INFO] processed 13000/20858\n",
      "[INFO] processed 14000/20858\n",
      "[INFO] processed 15000/20858\n",
      "[INFO] processed 16000/20858\n",
      "[INFO] processed 17000/20858\n",
      "[INFO] processed 18000/20858\n",
      "[INFO] processed 19000/20858\n",
      "[INFO] processed 20000/20858\n"
     ]
    }
   ],
   "source": [
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    image = cv2.imread(imagePath)\n",
    "    label = imagePath.split('/')[1].split('(')[0]\n",
    "    image = cv2.resize(image, (28,28))\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    #images = np.append(images, [image], axis=0)\n",
    "    labels.append(label)\n",
    "    rawImages.append(image)\n",
    "    \n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        print(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20858, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_array = np.array(rawImages)\n",
    "images_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images_array, np.array(labels), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data :  {'0': 778, '1': 537, '10': 781, '11': 852, '12': 874, '13': 941, '14': 853, '15': 764, '16': 752, '17': 942, '18': 762, '19': 955, '2': 1113, '3': 1028, '4': 895, '5': 777, '6': 713, '7': 776, '8': 920, '9': 673}\n"
     ]
    }
   ],
   "source": [
    "unique , counts = np.unique(y_train,return_counts = True)\n",
    "print('Train data : ',dict(zip(unique,counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data :  {'0': 179, '1': 133, '10': 168, '11': 214, '12': 205, '13': 235, '14': 235, '15': 182, '16': 215, '17': 213, '18': 188, '19': 250, '2': 307, '3': 244, '4': 249, '5': 221, '6': 185, '7': 184, '8': 212, '9': 153}\n"
     ]
    }
   ],
   "source": [
    "unique , counts = np.unique(y_test,return_counts = True)\n",
    "print('Test data : ',dict(zip(unique,counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "num_label = len(np.unique(y_train)) #10 labels\n",
    "print(num_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16686, 28, 28)\n",
      "(4172, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],28,28,1).astype('float32')/255\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout,Flatten,MaxPooling2D,Conv2D\n",
    "from keras.utils import to_categorical,plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 20\n",
    "y_train = to_categorical(y_train,n_class)\n",
    "y_test = to_categorical(y_test,n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#model MLP 3 layer\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation = 'relu',input_shape = (28,28,1)))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense((128),activation='relu'))\n",
    "model.add(Dropout((0.5)))\n",
    "\n",
    "model.add(Dense(n_class,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\c3000094\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "16686/16686 [==============================] - 14s 830us/step - loss: 1.0807 - acc: 0.7078\n",
      "Epoch 2/15\n",
      "16686/16686 [==============================] - 13s 778us/step - loss: 0.1791 - acc: 0.9536\n",
      "Epoch 3/15\n",
      "16686/16686 [==============================] - 13s 784us/step - loss: 0.1099 - acc: 0.9710\n",
      "Epoch 4/15\n",
      "16686/16686 [==============================] - 13s 802us/step - loss: 0.0794 - acc: 0.9775\n",
      "Epoch 5/15\n",
      "16686/16686 [==============================] - 13s 800us/step - loss: 0.0621 - acc: 0.9815\n",
      "Epoch 6/15\n",
      "16686/16686 [==============================] - 13s 764us/step - loss: 0.0509 - acc: 0.9853\n",
      "Epoch 7/15\n",
      "16686/16686 [==============================] - 13s 770us/step - loss: 0.0418 - acc: 0.9888\n",
      "Epoch 8/15\n",
      "16686/16686 [==============================] - 13s 758us/step - loss: 0.0389 - acc: 0.9881\n",
      "Epoch 9/15\n",
      "16686/16686 [==============================] - 13s 787us/step - loss: 0.0352 - acc: 0.9895\n",
      "Epoch 10/15\n",
      "16686/16686 [==============================] - 13s 791us/step - loss: 0.0309 - acc: 0.9905\n",
      "Epoch 11/15\n",
      "16686/16686 [==============================] - 13s 773us/step - loss: 0.0273 - acc: 0.9914\n",
      "Epoch 12/15\n",
      "16686/16686 [==============================] - 13s 778us/step - loss: 0.0298 - acc: 0.9902\n",
      "Epoch 13/15\n",
      "16686/16686 [==============================] - 13s 787us/step - loss: 0.0247 - acc: 0.9916\n",
      "Epoch 14/15\n",
      "16686/16686 [==============================] - 13s 790us/step - loss: 0.0217 - acc: 0.9928\n",
      "Epoch 15/15\n",
      "16686/16686 [==============================] - 13s 766us/step - loss: 0.0228 - acc: 0.9919\n",
      "4172/4172 [==============================] - 1s 257us/step\n",
      "ACCURANCY : 99.44870565675934\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train , epochs = 15 , batch_size =128)\n",
    "score =model.evaluate(X_test,y_test ,batch_size = 128)\n",
    "print(\"ACCURANCY : \" + str(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model.predict(X_test)\n",
    "y_pred =np.argmax(value,axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       179\n",
      "           1       1.00      0.98      0.99       133\n",
      "           2       1.00      0.99      1.00       307\n",
      "           3       1.00      1.00      1.00       244\n",
      "           4       0.99      1.00      0.99       249\n",
      "           5       0.97      0.98      0.98       221\n",
      "           6       0.98      0.98      0.98       185\n",
      "           7       1.00      0.99      1.00       184\n",
      "           8       0.99      0.99      0.99       212\n",
      "           9       0.97      0.99      0.98       153\n",
      "          10       1.00      1.00      1.00       168\n",
      "          11       1.00      1.00      1.00       214\n",
      "          12       1.00      1.00      1.00       205\n",
      "          13       1.00      1.00      1.00       235\n",
      "          14       1.00      1.00      1.00       235\n",
      "          15       1.00      1.00      1.00       182\n",
      "          16       0.99      1.00      1.00       215\n",
      "          17       1.00      1.00      1.00       213\n",
      "          18       1.00      1.00      1.00       188\n",
      "          19       1.00      1.00      1.00       250\n",
      "\n",
      "    accuracy                           0.99      4172\n",
      "   macro avg       0.99      0.99      0.99      4172\n",
      "weighted avg       0.99      0.99      0.99      4172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_number(num):\n",
    "    if num < 10 : return num\n",
    "    elif num == 10 : return 0\n",
    "    elif num == 11 : return 1\n",
    "    elif num == 12 : return 2\n",
    "    elif num == 13 : return 3\n",
    "    elif num == 14 : return 4\n",
    "    elif num == 15 : return 5\n",
    "    elif num == 16 : return 6\n",
    "    elif num == 17 : return 7\n",
    "    elif num == 18 : return 8\n",
    "    else  : return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_tensorflow2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
